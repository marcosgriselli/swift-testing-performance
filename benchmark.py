#!/usr/bin/env python3

import argparse
import subprocess
import shutil

_MAX_NUMBER_OF_TEST_FILES = 10


def _xctest_test_file(test_index: int) -> str:
    return f"CompilePerformance/XCTestTests/XCTestTests{test_index}.swift"


def _swift_testing_test_file(test_index: int) -> str:
    return f"CompilePerformance/SwiftTestingTests/SwiftTestingTests{test_index}.swift"


def _cleanup_test_files() -> None:
    test_files = [
        _xctest_test_file(file_index) for file_index in range(_MAX_NUMBER_OF_TEST_FILES)
    ]
    test_files.extend(
        [
            _swift_testing_test_file(file_index)
            for file_index in range(_MAX_NUMBER_OF_TEST_FILES)
        ]
    )

    for test_file in test_files:
        with open(test_file, "w") as f:
            f.write("")


def _generate_xctest_tests(test_count: int, test_files: int) -> None:
    tests_per_file = int(test_count / test_files)
    for file_index in range(test_files):
        test_file = _xctest_test_file(file_index)
        with open(test_file, "w") as f:
            f.write(
                f"""// This file is generated by generate_tests.py
import XCTest

final class XCTestTests{file_index}: XCTestCase {{
"""
            )
            for i in range(tests_per_file):
                f.write(
                    f"""
    func testExample{i}() {{
        XCTAssert({i} == {i})
    }}
"""
                )
            f.write("}\n")


def _generate_swift_testing_tests(test_count: int, test_files: int) -> None:
    tests_per_file = int(test_count / test_files)
    for file_index in range(test_files):
        test_file = _swift_testing_test_file(file_index)
        with open(test_file, "w") as f:
            f.write(
                f"""// This file is generated by generate_tests.py
import Testing

struct SwiftTestingTests{file_index} {{
"""
            )
            for i in range(tests_per_file):
                f.write(
                    f"""
    @Test
    func testExample{i}() {{
        #expect({i} == {i})
    }}
"""
                )
            f.write("}\n")


def _xcodebuild_command(scheme: str) -> str:
    project = "-project CompilePerformance/CompilePerformance.xcodeproj"
    destination = "-destination 'platform=iOS Simulator,name=iPhone 15,OS=18.0'"
    return f"xcodebuild {project} -scheme {scheme} {destination} build"


def _benchmark_tests(test_count: int, test_files: int, runs: int) -> None:
    _cleanup_test_files()
    _generate_swift_testing_tests(test_count, test_files)
    _generate_xctest_tests(test_count, test_files)

    swift_testing_command = _xcodebuild_command("SwiftTestingTests")
    xctest_command = _xcodebuild_command("XCTestTests")

    hyperfine = shutil.which("hyperfine")
    if not hyperfine:
        print(
            "hyperfine is not installed. Install it from: https://github.com/sharkdp/hyperfine?tab=readme-ov-file#installation."
        )
        print(
            "Alternatively, you can either build the tests suites in Xcode or run the commands manually:"
        )
        print(f"SwiftTesting: {swift_testing_command}")
        print(f"XCTest: {xctest_command}")
        return

    cleanup_command = "rm -rf ~/Library/Developer/Xcode/DerivedData/CompilePerformance-* && xcodebuild clean -project CompilePerformance/CompilePerformance.xcodeproj || true"
    test_and_file_count_comment = f"{test_count} tests in {test_files} files"
    subprocess.run(
        [
            hyperfine,
            "--runs",
            str(runs),
            "--prepare",
            cleanup_command,
            "--command-name",
            f"XCTest ({test_and_file_count_comment})",
            xctest_command,
            "--command-name",
            f"SwiftTesting ({test_and_file_count_comment})",
            swift_testing_command,
        ]
    )


def _build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--test_count", help="The number of tests to generate", type=int, required=True
    )
    parser.add_argument(
        "--test_files",
        help="The number of test files to generate",
        type=int,
        default=1,
        choices=range(1, _MAX_NUMBER_OF_TEST_FILES + 1),
    )
    parser.add_argument(
        "--runs",
        help="The number of compile runs to perform for each test suite",
        type=int,
        default=3,
    )

    return parser


def _main(args: argparse.Namespace) -> None:
    test_count = int(args.test_count)
    test_files = int(args.test_files)
    runs = int(args.runs)
    _benchmark_tests(test_count, test_files, runs)


if __name__ == "__main__":
    _main(_build_parser().parse_args())
